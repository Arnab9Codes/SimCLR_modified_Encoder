{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthalles/SimCLR/blob/simclr-refactor/feature_eval/mini_batch_logistic_regression_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YUemQib7ZE4D"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/aktarafder/Documents/DeepLearning/env1/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSgRE1CcLqdS",
        "outputId": "48a2ae15-f672-495b-8d43-9a23b85fa3b8"
      },
      "outputs": [],
      "source": [
        "#!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = torchvision.models.squeezenet1_0(pretrained=False, num_classes=10).to(device)\n",
        "#additional_fc_layer = nn.Sequential(nn.Linear(1000, 512), nn.ReLU(), nn.Linear(512, 10))\n",
        "#model=nn.Sequential(model, additional_fc_layer).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SqueezeNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (3): Fire(\n",
              "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Fire(\n",
              "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Fire(\n",
              "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (7): Fire(\n",
              "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Fire(\n",
              "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Fire(\n",
              "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Fire(\n",
              "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (12): Fire(\n",
              "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"for name, param in model.named_parameters():\\n    if not name.startswith('1.'):\\n        param.requires_grad = False\\n        print(name)\\n\\nparameters = list(filter(lambda p: p.requires_grad, model.parameters()))\\n#print(parameters.name)\\nassert len(parameters) == 4  # fc.weight, fc.bias\""
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# freeze all layers but the last fc\n",
        "'''for name, param in model.named_parameters():\n",
        "    if not name.startswith('1.'):\n",
        "        param.requires_grad = False\n",
        "        print(name)\n",
        "\n",
        "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "#print(parameters.name)\n",
        "assert len(parameters) == 4  # fc.weight, fc.bias'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "NOIJEui1ZziV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'def get_file_id_by_model(folder_name):\\n  file_id = {\\'resnet18_100-epochs_stl10\\': \\'14_nH2FkyKbt61cieQDiSbBVNP8-gtwgF\\',\\n             \\'resnet18_100-epochs_cifar10\\': \\'1lc2aoVtrAetGn0PnTkOyFzPCIucOJq7C\\',\\n             \\'resnet50_50-epochs_stl10\\': \\'1ByTKAUsdm_X7tLcii6oAEl5qFRqRMZSu\\'}\\n  return file_id.get(folder_name, \"Model not found.\")'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''def get_file_id_by_model(folder_name):\n",
        "  file_id = {'resnet18_100-epochs_stl10': '14_nH2FkyKbt61cieQDiSbBVNP8-gtwgF',\n",
        "             'resnet18_100-epochs_cifar10': '1lc2aoVtrAetGn0PnTkOyFzPCIucOJq7C',\n",
        "             'resnet50_50-epochs_stl10': '1ByTKAUsdm_X7tLcii6oAEl5qFRqRMZSu'}\n",
        "  return file_id.get(folder_name, \"Model not found.\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7YMxsvEZMrX",
        "outputId": "59475430-69d2-45a2-b61b-ae755d5d6e88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"folder_name = 'resnet50_50-epochs_stl10'\\nfile_id = get_file_id_by_model(folder_name)\\nprint(folder_name, file_id)\""
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''folder_name = 'resnet50_50-epochs_stl10'\n",
        "file_id = get_file_id_by_model(folder_name)\n",
        "print(folder_name, file_id)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWZ8fet_YoJm",
        "outputId": "fbaeb858-221b-4d1b-dd90-001a6e713b75"
      },
      "outputs": [],
      "source": [
        "# download and extract model files\n",
        "#os.system('gdown https://drive.google.com/uc?id={}'.format(file_id))\n",
        "#os.system('unzip {}'.format(folder_name))\n",
        "#!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'import zipfile\\nimport os\\n\\nzip_file = \"resnet50_50-epochs_stl10.zip\"\\n\\n# Get the current directory where the ZIP file is located\\ncurrent_directory = os.path.dirname(os.path.abspath(zip_file))\\n\\n# Open the ZIP file for reading\\nwith zipfile.ZipFile(zip_file, \\'r\\') as zip_ref:\\n    # Extract all the contents into the same folder\\n    zip_ref.extractall(current_directory)\\n'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''import zipfile\n",
        "import os\n",
        "\n",
        "zip_file = \"resnet50_50-epochs_stl10.zip\"\n",
        "\n",
        "# Get the current directory where the ZIP file is located\n",
        "current_directory = os.path.dirname(os.path.abspath(zip_file))\n",
        "\n",
        "# Open the ZIP file for reading\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    # Extract all the contents into the same folder\n",
        "    zip_ref.extractall(current_directory)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " checkpoint_0005.pth.tar\n",
            " config.yml\n",
            " data\n",
            " events.out.tfevents.1610927742.4cb2c837708d.2694093.0\n",
            " Sqeezenet_mini_batch_logistic_regression_evaluator.ipynb\n",
            " squeeze_checkpoint_0100.pth.tar\n",
            " squeezenet_checkpoint_0001.pth.tar\n",
            " squeezenet_checkpoint_0010cifar.pth.tar\n",
            "'squeezenet_checkpoint_0010.pth copy.tar'\n",
            " squeezenet_checkpoint_0010.pth.tar\n",
            "'squeezenet_checkpoint_0100.pth no fc.tar'\n",
            " squeezenet_checkpoint_0100.pth.tar\n",
            " training.log\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'import os\\n\\nzip_file = \"resnet50_50-epochs_stl10.zip\"\\n\\n# Get the size of the ZIP file in bytes\\nfile_size_bytes = os.path.getsize(zip_file)\\n\\n# Convert bytes to a human-readable format (e.g., kilobytes, megabytes, etc.)\\ndef convert_size(size_bytes):\\n    # Size conversion\\n    for unit in [\\'bytes\\', \\'KB\\', \\'MB\\', \\'GB\\', \\'TB\\']:\\n        if size_bytes < 1024.0:\\n            return f\"{size_bytes:.2f} {unit}\"\\n        size_bytes /= 1024.0\\n\\n# Get human-readable file size\\nfile_size_human_readable = convert_size(file_size_bytes)\\n\\nprint(f\"The size of \\'{zip_file}\\' is: {file_size_human_readable}\")\\n'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''import os\n",
        "\n",
        "zip_file = \"resnet50_50-epochs_stl10.zip\"\n",
        "\n",
        "# Get the size of the ZIP file in bytes\n",
        "file_size_bytes = os.path.getsize(zip_file)\n",
        "\n",
        "# Convert bytes to a human-readable format (e.g., kilobytes, megabytes, etc.)\n",
        "def convert_size(size_bytes):\n",
        "    # Size conversion\n",
        "    for unit in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
        "        if size_bytes < 1024.0:\n",
        "            return f\"{size_bytes:.2f} {unit}\"\n",
        "        size_bytes /= 1024.0\n",
        "\n",
        "# Get human-readable file size\n",
        "file_size_human_readable = convert_size(file_size_bytes)\n",
        "\n",
        "print(f\"The size of '{zip_file}' is: {file_size_human_readable}\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "3_nypQVEv-hn"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "BfIPl0G6_RrT"
      },
      "outputs": [],
      "source": [
        "def get_stl10_data_loaders(download, shuffle=False, batch_size=256):\n",
        "  train_dataset = datasets.STL10('./data', split='train', download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                            num_workers=0, drop_last=False, shuffle=shuffle)\n",
        "  \n",
        "  test_dataset = datasets.STL10('./data', split='test', download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "                            num_workers=10, drop_last=False, shuffle=shuffle)\n",
        "  return train_loader, test_loader\n",
        "\n",
        "def get_cifar10_data_loaders(download, shuffle=False, batch_size=256):\n",
        "  train_dataset = datasets.CIFAR10('./data', train=True, download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                            num_workers=0, drop_last=False, shuffle=shuffle)\n",
        "  \n",
        "  test_dataset = datasets.CIFAR10('./data', train=False, download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "                            num_workers=10, drop_last=False, shuffle=shuffle)\n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "6N8lYkbmDTaK"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join('./config.yml')) as file:\n",
        "  config = yaml.load(file, Loader=yaml.FullLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "a18lPD-tIle6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'if config[\\'arch\\'] == \\'resnet18\\':\\n  model = torchvision.models.resnet18(pretrained=False, num_classes=10).to(device)\\nelif config[\\'arch\\'] == \\'resnet50\\':\\n  model = torchvision.models.resnet50(pretrained=False, num_classes=10).to(device)\\nelif config[\\'arch\\'] == \\'squeezenet\\':\\n  print(\"squeezenet\")\\n  model = torchvision.models.squeezenet1_0(pretrained=False).to(device).to(device)\\n  # or use squeezenet1_1 depending on the version you want'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''if config['arch'] == 'resnet18':\n",
        "  model = torchvision.models.resnet18(pretrained=False, num_classes=10).to(device)\n",
        "elif config['arch'] == 'resnet50':\n",
        "  model = torchvision.models.resnet50(pretrained=False, num_classes=10).to(device)\n",
        "elif config['arch'] == 'squeezenet':\n",
        "  print(\"squeezenet\")\n",
        "  model = torchvision.models.squeezenet1_0(pretrained=False).to(device).to(device)\n",
        "  # or use squeezenet1_1 depending on the version you want'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'rmodel=model = torchvision.models.resnet18(pretrained=False).to(device)\\nrmodel'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''rmodel=model = torchvision.models.resnet18(pretrained=False).to(device)\n",
        "rmodel'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['backbone.features.0.weight', 'backbone.features.0.bias', 'backbone.features.3.squeeze.weight', 'backbone.features.3.squeeze.bias', 'backbone.features.3.expand1x1.weight', 'backbone.features.3.expand1x1.bias', 'backbone.features.3.expand3x3.weight', 'backbone.features.3.expand3x3.bias', 'backbone.features.4.squeeze.weight', 'backbone.features.4.squeeze.bias', 'backbone.features.4.expand1x1.weight', 'backbone.features.4.expand1x1.bias', 'backbone.features.4.expand3x3.weight', 'backbone.features.4.expand3x3.bias', 'backbone.features.5.squeeze.weight', 'backbone.features.5.squeeze.bias', 'backbone.features.5.expand1x1.weight', 'backbone.features.5.expand1x1.bias', 'backbone.features.5.expand3x3.weight', 'backbone.features.5.expand3x3.bias', 'backbone.features.7.squeeze.weight', 'backbone.features.7.squeeze.bias', 'backbone.features.7.expand1x1.weight', 'backbone.features.7.expand1x1.bias', 'backbone.features.7.expand3x3.weight', 'backbone.features.7.expand3x3.bias', 'backbone.features.8.squeeze.weight', 'backbone.features.8.squeeze.bias', 'backbone.features.8.expand1x1.weight', 'backbone.features.8.expand1x1.bias', 'backbone.features.8.expand3x3.weight', 'backbone.features.8.expand3x3.bias', 'backbone.features.9.squeeze.weight', 'backbone.features.9.squeeze.bias', 'backbone.features.9.expand1x1.weight', 'backbone.features.9.expand1x1.bias', 'backbone.features.9.expand3x3.weight', 'backbone.features.9.expand3x3.bias', 'backbone.features.10.squeeze.weight', 'backbone.features.10.squeeze.bias', 'backbone.features.10.expand1x1.weight', 'backbone.features.10.expand1x1.bias', 'backbone.features.10.expand3x3.weight', 'backbone.features.10.expand3x3.bias', 'backbone.features.12.squeeze.weight', 'backbone.features.12.squeeze.bias', 'backbone.features.12.expand1x1.weight', 'backbone.features.12.expand1x1.bias', 'backbone.features.12.expand3x3.weight', 'backbone.features.12.expand3x3.bias', 'backbone.classifier.1.weight', 'backbone.classifier.1.bias'])\n"
          ]
        }
      ],
      "source": [
        "checkpoint = torch.load('squeezenet_checkpoint_0100.pth no fc.tar', map_location=device)\n",
        "state_dict = checkpoint['state_dict']\n",
        "print(state_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "52\n"
          ]
        }
      ],
      "source": [
        "print(len(state_dict.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "4AIfgq41GuTT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "backbone.features.0.weight\n",
            "backbone.features.0.bias\n",
            "backbone.features.3.squeeze.weight\n",
            "backbone.features.3.squeeze.bias\n",
            "backbone.features.3.expand1x1.weight\n",
            "backbone.features.3.expand1x1.bias\n",
            "backbone.features.3.expand3x3.weight\n",
            "backbone.features.3.expand3x3.bias\n",
            "backbone.features.4.squeeze.weight\n",
            "backbone.features.4.squeeze.bias\n",
            "backbone.features.4.expand1x1.weight\n",
            "backbone.features.4.expand1x1.bias\n",
            "backbone.features.4.expand3x3.weight\n",
            "backbone.features.4.expand3x3.bias\n",
            "backbone.features.5.squeeze.weight\n",
            "backbone.features.5.squeeze.bias\n",
            "backbone.features.5.expand1x1.weight\n",
            "backbone.features.5.expand1x1.bias\n",
            "backbone.features.5.expand3x3.weight\n",
            "backbone.features.5.expand3x3.bias\n",
            "backbone.features.7.squeeze.weight\n",
            "backbone.features.7.squeeze.bias\n",
            "backbone.features.7.expand1x1.weight\n",
            "backbone.features.7.expand1x1.bias\n",
            "backbone.features.7.expand3x3.weight\n",
            "backbone.features.7.expand3x3.bias\n",
            "backbone.features.8.squeeze.weight\n",
            "backbone.features.8.squeeze.bias\n",
            "backbone.features.8.expand1x1.weight\n",
            "backbone.features.8.expand1x1.bias\n",
            "backbone.features.8.expand3x3.weight\n",
            "backbone.features.8.expand3x3.bias\n",
            "backbone.features.9.squeeze.weight\n",
            "backbone.features.9.squeeze.bias\n",
            "backbone.features.9.expand1x1.weight\n",
            "backbone.features.9.expand1x1.bias\n",
            "backbone.features.9.expand3x3.weight\n",
            "backbone.features.9.expand3x3.bias\n",
            "backbone.features.10.squeeze.weight\n",
            "backbone.features.10.squeeze.bias\n",
            "backbone.features.10.expand1x1.weight\n",
            "backbone.features.10.expand1x1.bias\n",
            "backbone.features.10.expand3x3.weight\n",
            "backbone.features.10.expand3x3.bias\n",
            "backbone.features.12.squeeze.weight\n",
            "backbone.features.12.squeeze.bias\n",
            "backbone.features.12.expand1x1.weight\n",
            "backbone.features.12.expand1x1.bias\n",
            "backbone.features.12.expand3x3.weight\n",
            "backbone.features.12.expand3x3.bias\n"
          ]
        }
      ],
      "source": [
        "#checkpoint = torch.load('checkpoint_0040.pth.tar', map_location=device)\n",
        "#checkpoint = torch.load('squeezenet_checkpoint_0001.pth.tar', map_location=device)\n",
        "checkpoint = torch.load('squeezenet_checkpoint_0100.pth no fc.tar', map_location=device)\n",
        "state_dict = checkpoint['state_dict']\n",
        "\n",
        "for k in list(state_dict.keys()):\n",
        "\n",
        "  if k.startswith('backbone.'):\n",
        "    #print(\"yes\")\n",
        "    if k.startswith('backbone') and not k.startswith('backbone.class'):\n",
        "      print(k)\n",
        "      # remove prefix\n",
        "      state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
        "\n",
        "  del state_dict[k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n"
          ]
        }
      ],
      "source": [
        "print(len(state_dict.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "VVjA83PPJYWl"
      },
      "outputs": [],
      "source": [
        "log = model.load_state_dict(state_dict, strict=False)\n",
        "#assert log.missing_keys == ['fc.weight', 'fc.bias']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['classifier.1.weight', 'classifier.1.bias'], unexpected_keys=[])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "#additional_fc_layer = torch.nn.Linear(1000, 10)\n",
        "\n",
        "# Access the existing classifier and add the additional FC layer\n",
        "#model.classifier.add_module('fc', additional_fc_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "149b9ce8fb68473a837a77431c12281a",
            "88cd3db2831e4c13a4a634709700d6b2",
            "a88c31d74f5c40a2b24bcff5a35d216c",
            "60c6150177694717a622936b830427b5",
            "dba019efadee4fdc8c799f309b9a7e70",
            "5901c2829a554c8ebbd5926610088041",
            "957362a11d174407979cf17012bf9208",
            "a4f82234388e4701a02a9f68a177193a"
          ]
        },
        "id": "_GC0a14uWRr6",
        "outputId": "4c2558db-921c-425e-f947-6cc746d8c749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Dataset: stl10\n"
          ]
        }
      ],
      "source": [
        "if config['dataset_name'] == 'cifar10':\n",
        "  train_loader, test_loader = get_cifar10_data_loaders(download=True)\n",
        "elif config['dataset_name'] == 'stl10':\n",
        "  train_loader, test_loader = get_stl10_data_loaders(download=True)\n",
        "print(\"Dataset:\", config['dataset_name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "pYT_KsM0Mnnr"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"for name, param in model.named_parameters():\\n    if name not in ['fc.weight', 'fc.bias']:\\n        param.requires_grad = False\\n\\nparameters = list(filter(lambda p: p.requires_grad, model.parameters()))\\nprint(parameters)\\nassert len(parameters) == 2  # fc.weight, fc.bias\""
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# freeze all layers but the last fc\n",
        "'''for name, param in model.named_parameters():\n",
        "    if name not in ['fc.weight', 'fc.bias']:\n",
        "        param.requires_grad = False\n",
        "\n",
        "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "print(parameters)\n",
        "assert len(parameters) == 2  # fc.weight, fc.bias'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['features.0.weight',\n",
              " 'features.0.bias',\n",
              " 'features.3.squeeze.weight',\n",
              " 'features.3.squeeze.bias',\n",
              " 'features.3.expand1x1.weight',\n",
              " 'features.3.expand1x1.bias',\n",
              " 'features.3.expand3x3.weight',\n",
              " 'features.3.expand3x3.bias',\n",
              " 'features.4.squeeze.weight',\n",
              " 'features.4.squeeze.bias',\n",
              " 'features.4.expand1x1.weight',\n",
              " 'features.4.expand1x1.bias',\n",
              " 'features.4.expand3x3.weight',\n",
              " 'features.4.expand3x3.bias',\n",
              " 'features.5.squeeze.weight',\n",
              " 'features.5.squeeze.bias',\n",
              " 'features.5.expand1x1.weight',\n",
              " 'features.5.expand1x1.bias',\n",
              " 'features.5.expand3x3.weight',\n",
              " 'features.5.expand3x3.bias',\n",
              " 'features.7.squeeze.weight',\n",
              " 'features.7.squeeze.bias',\n",
              " 'features.7.expand1x1.weight',\n",
              " 'features.7.expand1x1.bias',\n",
              " 'features.7.expand3x3.weight',\n",
              " 'features.7.expand3x3.bias',\n",
              " 'features.8.squeeze.weight',\n",
              " 'features.8.squeeze.bias',\n",
              " 'features.8.expand1x1.weight',\n",
              " 'features.8.expand1x1.bias',\n",
              " 'features.8.expand3x3.weight',\n",
              " 'features.8.expand3x3.bias',\n",
              " 'features.9.squeeze.weight',\n",
              " 'features.9.squeeze.bias',\n",
              " 'features.9.expand1x1.weight',\n",
              " 'features.9.expand1x1.bias',\n",
              " 'features.9.expand3x3.weight',\n",
              " 'features.9.expand3x3.bias',\n",
              " 'features.10.squeeze.weight',\n",
              " 'features.10.squeeze.bias',\n",
              " 'features.10.expand1x1.weight',\n",
              " 'features.10.expand1x1.bias',\n",
              " 'features.10.expand3x3.weight',\n",
              " 'features.10.expand3x3.bias',\n",
              " 'features.12.squeeze.weight',\n",
              " 'features.12.squeeze.bias',\n",
              " 'features.12.expand1x1.weight',\n",
              " 'features.12.expand1x1.bias',\n",
              " 'features.12.expand3x3.weight',\n",
              " 'features.12.expand3x3.bias']"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(state_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features.0.weight\n",
            "features.0.bias\n",
            "features.3.squeeze.weight\n",
            "features.3.squeeze.bias\n",
            "features.3.expand1x1.weight\n",
            "features.3.expand1x1.bias\n",
            "features.3.expand3x3.weight\n",
            "features.3.expand3x3.bias\n",
            "features.4.squeeze.weight\n",
            "features.4.squeeze.bias\n",
            "features.4.expand1x1.weight\n",
            "features.4.expand1x1.bias\n",
            "features.4.expand3x3.weight\n",
            "features.4.expand3x3.bias\n",
            "features.5.squeeze.weight\n",
            "features.5.squeeze.bias\n",
            "features.5.expand1x1.weight\n",
            "features.5.expand1x1.bias\n",
            "features.5.expand3x3.weight\n",
            "features.5.expand3x3.bias\n",
            "features.7.squeeze.weight\n",
            "features.7.squeeze.bias\n",
            "features.7.expand1x1.weight\n",
            "features.7.expand1x1.bias\n",
            "features.7.expand3x3.weight\n",
            "features.7.expand3x3.bias\n",
            "features.8.squeeze.weight\n",
            "features.8.squeeze.bias\n",
            "features.8.expand1x1.weight\n",
            "features.8.expand1x1.bias\n",
            "features.8.expand3x3.weight\n",
            "features.8.expand3x3.bias\n",
            "features.9.squeeze.weight\n",
            "features.9.squeeze.bias\n",
            "features.9.expand1x1.weight\n",
            "features.9.expand1x1.bias\n",
            "features.9.expand3x3.weight\n",
            "features.9.expand3x3.bias\n",
            "features.10.squeeze.weight\n",
            "features.10.squeeze.bias\n",
            "features.10.expand1x1.weight\n",
            "features.10.expand1x1.bias\n",
            "features.10.expand3x3.weight\n",
            "features.10.expand3x3.bias\n",
            "features.12.squeeze.weight\n",
            "features.12.squeeze.bias\n",
            "features.12.expand1x1.weight\n",
            "features.12.expand1x1.bias\n",
            "features.12.expand3x3.weight\n",
            "features.12.expand3x3.bias\n"
          ]
        }
      ],
      "source": [
        "# freeze all layers but the last fc\n",
        "for name, param in model.named_parameters():\n",
        "    #if not (name.startswith('1.') or name.startswith('0.class')):\n",
        "    if not name.startswith('class'):\n",
        "        param.requires_grad = False\n",
        "        print(name)\n",
        "\n",
        "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "#print(parameters.name)\n",
        "#assert len(parameters) == 2  # fc.weight, fc.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "print(len(parameters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parameters[0].shape;\n",
        "parameters[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "aPVh1S_eMRDU"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0008)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "edr6RhP2PdVq"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOder0dAMI7X",
        "outputId": "5f723b91-5a5e-43eb-ca01-a9b5ae2f1346"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/aktarafder/Documents/DeepLearning/env1/lib/python3.7/site-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
            "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\tTop1 Train accuracy 19.292280197143555\tTop1 Test accuracy: 29.86572265625\tTop5 test acc: 73.9306640625\n",
            "Epoch 1\tTop1 Train accuracy 36.11328125\tTop1 Test accuracy: 40.49560546875\tTop5 test acc: 86.1328125\n",
            "Epoch 2\tTop1 Train accuracy 44.04641342163086\tTop1 Test accuracy: 46.53564453125\tTop5 test acc: 91.09375\n",
            "Epoch 3\tTop1 Train accuracy 49.49793243408203\tTop1 Test accuracy: 50.185546875\tTop5 test acc: 93.50830078125\n",
            "Epoch 4\tTop1 Train accuracy 53.681068420410156\tTop1 Test accuracy: 53.515625\tTop5 test acc: 94.6630859375\n",
            "Epoch 5\tTop1 Train accuracy 56.07881546020508\tTop1 Test accuracy: 55.21240234375\tTop5 test acc: 95.185546875\n",
            "Epoch 6\tTop1 Train accuracy 58.5822639465332\tTop1 Test accuracy: 55.84228515625\tTop5 test acc: 95.68603515625\n",
            "Epoch 7\tTop1 Train accuracy 58.772979736328125\tTop1 Test accuracy: 56.728515625\tTop5 test acc: 95.73974609375\n",
            "Epoch 8\tTop1 Train accuracy 60.64567947387695\tTop1 Test accuracy: 57.9150390625\tTop5 test acc: 95.888671875\n",
            "Epoch 9\tTop1 Train accuracy 60.406707763671875\tTop1 Test accuracy: 57.890625\tTop5 test acc: 96.50390625\n",
            "Epoch 10\tTop1 Train accuracy 61.571693420410156\tTop1 Test accuracy: 58.8037109375\tTop5 test acc: 96.59912109375\n",
            "Epoch 11\tTop1 Train accuracy 62.294349670410156\tTop1 Test accuracy: 59.12109375\tTop5 test acc: 96.63330078125\n",
            "Epoch 12\tTop1 Train accuracy 62.763099670410156\tTop1 Test accuracy: 59.72412109375\tTop5 test acc: 96.5185546875\n",
            "Epoch 13\tTop1 Train accuracy 63.444393157958984\tTop1 Test accuracy: 59.88525390625\tTop5 test acc: 96.71875\n",
            "Epoch 14\tTop1 Train accuracy 63.34558868408203\tTop1 Test accuracy: 60.25390625\tTop5 test acc: 96.79443359375\n",
            "Epoch 15\tTop1 Train accuracy 64.4312973022461\tTop1 Test accuracy: 59.970703125\tTop5 test acc: 96.9970703125\n",
            "Epoch 16\tTop1 Train accuracy 64.41980743408203\tTop1 Test accuracy: 60.654296875\tTop5 test acc: 97.1240234375\n",
            "Epoch 17\tTop1 Train accuracy 64.69438934326172\tTop1 Test accuracy: 60.2099609375\tTop5 test acc: 97.0556640625\n",
            "Epoch 18\tTop1 Train accuracy 65.45037078857422\tTop1 Test accuracy: 61.41357421875\tTop5 test acc: 97.2021484375\n",
            "Epoch 19\tTop1 Train accuracy 65.07353210449219\tTop1 Test accuracy: 61.32080078125\tTop5 test acc: 96.98486328125\n",
            "Epoch 20\tTop1 Train accuracy 65.7835464477539\tTop1 Test accuracy: 61.52099609375\tTop5 test acc: 97.18994140625\n",
            "Epoch 21\tTop1 Train accuracy 66.29480743408203\tTop1 Test accuracy: 61.591796875\tTop5 test acc: 97.20703125\n",
            "Epoch 22\tTop1 Train accuracy 66.18451690673828\tTop1 Test accuracy: 61.1767578125\tTop5 test acc: 97.18505859375\n",
            "Epoch 23\tTop1 Train accuracy 65.82491302490234\tTop1 Test accuracy: 62.4072265625\tTop5 test acc: 97.197265625\n",
            "Epoch 24\tTop1 Train accuracy 67.46438598632812\tTop1 Test accuracy: 62.1044921875\tTop5 test acc: 97.24609375\n",
            "Epoch 25\tTop1 Train accuracy 66.5843276977539\tTop1 Test accuracy: 62.15576171875\tTop5 test acc: 97.12158203125\n",
            "Epoch 26\tTop1 Train accuracy 66.64867401123047\tTop1 Test accuracy: 62.28271484375\tTop5 test acc: 97.138671875\n",
            "Epoch 27\tTop1 Train accuracy 66.87040710449219\tTop1 Test accuracy: 62.41455078125\tTop5 test acc: 97.20947265625\n",
            "Epoch 28\tTop1 Train accuracy 67.1897964477539\tTop1 Test accuracy: 62.5048828125\tTop5 test acc: 97.21435546875\n",
            "Epoch 29\tTop1 Train accuracy 67.11742401123047\tTop1 Test accuracy: 62.71484375\tTop5 test acc: 97.17529296875\n",
            "Epoch 30\tTop1 Train accuracy 67.53446960449219\tTop1 Test accuracy: 62.822265625\tTop5 test acc: 97.18505859375\n",
            "Epoch 31\tTop1 Train accuracy 68.26516723632812\tTop1 Test accuracy: 62.68310546875\tTop5 test acc: 97.412109375\n",
            "Epoch 32\tTop1 Train accuracy 68.15258026123047\tTop1 Test accuracy: 62.54638671875\tTop5 test acc: 97.4462890625\n",
            "Epoch 33\tTop1 Train accuracy 68.37776184082031\tTop1 Test accuracy: 63.06884765625\tTop5 test acc: 97.44384765625\n",
            "Epoch 34\tTop1 Train accuracy 68.47771453857422\tTop1 Test accuracy: 63.15673828125\tTop5 test acc: 97.31689453125\n",
            "Epoch 35\tTop1 Train accuracy 68.42945861816406\tTop1 Test accuracy: 63.28857421875\tTop5 test acc: 97.42431640625\n",
            "Epoch 36\tTop1 Train accuracy 69.08318328857422\tTop1 Test accuracy: 63.4716796875\tTop5 test acc: 97.3974609375\n",
            "Epoch 37\tTop1 Train accuracy 69.36811065673828\tTop1 Test accuracy: 63.5546875\tTop5 test acc: 97.46826171875\n",
            "Epoch 38\tTop1 Train accuracy 69.07858276367188\tTop1 Test accuracy: 63.6279296875\tTop5 test acc: 97.36328125\n",
            "Epoch 39\tTop1 Train accuracy 69.15901184082031\tTop1 Test accuracy: 63.359375\tTop5 test acc: 97.39990234375\n",
            "Epoch 40\tTop1 Train accuracy 69.11994934082031\tTop1 Test accuracy: 63.11279296875\tTop5 test acc: 97.50732421875\n",
            "Epoch 41\tTop1 Train accuracy 69.76448059082031\tTop1 Test accuracy: 63.70849609375\tTop5 test acc: 97.5341796875\n",
            "Epoch 42\tTop1 Train accuracy 69.48299407958984\tTop1 Test accuracy: 62.94189453125\tTop5 test acc: 97.421875\n",
            "Epoch 43\tTop1 Train accuracy 69.20496368408203\tTop1 Test accuracy: 63.12255859375\tTop5 test acc: 97.5537109375\n",
            "Epoch 44\tTop1 Train accuracy 69.95519256591797\tTop1 Test accuracy: 63.193359375\tTop5 test acc: 97.56591796875\n",
            "Epoch 45\tTop1 Train accuracy 70.30905151367188\tTop1 Test accuracy: 63.0908203125\tTop5 test acc: 97.34375\n",
            "Epoch 46\tTop1 Train accuracy 70.19186401367188\tTop1 Test accuracy: 64.0673828125\tTop5 test acc: 97.67822265625\n",
            "Epoch 47\tTop1 Train accuracy 70.82146453857422\tTop1 Test accuracy: 63.33984375\tTop5 test acc: 97.56591796875\n",
            "Epoch 48\tTop1 Train accuracy 71.10294342041016\tTop1 Test accuracy: 64.05029296875\tTop5 test acc: 97.51708984375\n",
            "Epoch 49\tTop1 Train accuracy 69.87706756591797\tTop1 Test accuracy: 64.14306640625\tTop5 test acc: 97.39501953125\n",
            "Epoch 50\tTop1 Train accuracy 70.44347381591797\tTop1 Test accuracy: 63.90625\tTop5 test acc: 97.65380859375\n",
            "Epoch 51\tTop1 Train accuracy 70.67784881591797\tTop1 Test accuracy: 63.57177734375\tTop5 test acc: 97.60498046875\n",
            "Epoch 52\tTop1 Train accuracy 71.25460052490234\tTop1 Test accuracy: 63.89892578125\tTop5 test acc: 97.6904296875\n",
            "Epoch 53\tTop1 Train accuracy 70.74333953857422\tTop1 Test accuracy: 63.5400390625\tTop5 test acc: 97.76123046875\n",
            "Epoch 54\tTop1 Train accuracy 70.51700592041016\tTop1 Test accuracy: 64.25537109375\tTop5 test acc: 97.666015625\n",
            "Epoch 55\tTop1 Train accuracy 71.17761993408203\tTop1 Test accuracy: 63.87939453125\tTop5 test acc: 97.6806640625\n",
            "Epoch 56\tTop1 Train accuracy 71.53032684326172\tTop1 Test accuracy: 63.8671875\tTop5 test acc: 97.5830078125\n",
            "Epoch 57\tTop1 Train accuracy 71.640625\tTop1 Test accuracy: 64.033203125\tTop5 test acc: 97.72216796875\n",
            "Epoch 58\tTop1 Train accuracy 70.93635559082031\tTop1 Test accuracy: 64.21875\tTop5 test acc: 97.80029296875\n",
            "Epoch 59\tTop1 Train accuracy 71.88188934326172\tTop1 Test accuracy: 63.0908203125\tTop5 test acc: 97.59033203125\n",
            "Epoch 60\tTop1 Train accuracy 70.80652618408203\tTop1 Test accuracy: 64.0673828125\tTop5 test acc: 97.61474609375\n",
            "Epoch 61\tTop1 Train accuracy 70.76287078857422\tTop1 Test accuracy: 64.16015625\tTop5 test acc: 97.6513671875\n",
            "Epoch 62\tTop1 Train accuracy 71.27872467041016\tTop1 Test accuracy: 64.12109375\tTop5 test acc: 97.6416015625\n",
            "Epoch 63\tTop1 Train accuracy 71.88419342041016\tTop1 Test accuracy: 64.27490234375\tTop5 test acc: 97.646484375\n",
            "Epoch 64\tTop1 Train accuracy 71.14659881591797\tTop1 Test accuracy: 64.13818359375\tTop5 test acc: 97.5341796875\n",
            "Epoch 65\tTop1 Train accuracy 71.90946960449219\tTop1 Test accuracy: 64.3017578125\tTop5 test acc: 97.63671875\n",
            "Epoch 66\tTop1 Train accuracy 71.8577651977539\tTop1 Test accuracy: 63.80859375\tTop5 test acc: 97.74658203125\n",
            "Epoch 67\tTop1 Train accuracy 71.98414611816406\tTop1 Test accuracy: 64.18212890625\tTop5 test acc: 97.578125\n",
            "Epoch 68\tTop1 Train accuracy 71.25919342041016\tTop1 Test accuracy: 64.51171875\tTop5 test acc: 97.55615234375\n",
            "Epoch 69\tTop1 Train accuracy 72.5390625\tTop1 Test accuracy: 63.92578125\tTop5 test acc: 97.5\n",
            "Epoch 70\tTop1 Train accuracy 72.54480743408203\tTop1 Test accuracy: 64.27490234375\tTop5 test acc: 97.61962890625\n",
            "Epoch 71\tTop1 Train accuracy 72.1507339477539\tTop1 Test accuracy: 64.2578125\tTop5 test acc: 97.62939453125\n",
            "Epoch 72\tTop1 Train accuracy 72.41613006591797\tTop1 Test accuracy: 64.40673828125\tTop5 test acc: 97.60986328125\n",
            "Epoch 73\tTop1 Train accuracy 72.76309967041016\tTop1 Test accuracy: 64.19677734375\tTop5 test acc: 97.75146484375\n",
            "Epoch 74\tTop1 Train accuracy 72.4977035522461\tTop1 Test accuracy: 64.0380859375\tTop5 test acc: 97.5341796875\n",
            "Epoch 75\tTop1 Train accuracy 72.02550506591797\tTop1 Test accuracy: 64.23828125\tTop5 test acc: 97.6904296875\n",
            "Epoch 76\tTop1 Train accuracy 72.04733276367188\tTop1 Test accuracy: 64.2431640625\tTop5 test acc: 97.666015625\n",
            "Epoch 77\tTop1 Train accuracy 72.1875\tTop1 Test accuracy: 63.88671875\tTop5 test acc: 97.68310546875\n",
            "Epoch 78\tTop1 Train accuracy 72.35179901123047\tTop1 Test accuracy: 64.072265625\tTop5 test acc: 97.6904296875\n",
            "Epoch 79\tTop1 Train accuracy 72.68497467041016\tTop1 Test accuracy: 63.8232421875\tTop5 test acc: 97.62939453125\n",
            "Epoch 80\tTop1 Train accuracy 73.3030776977539\tTop1 Test accuracy: 64.24072265625\tTop5 test acc: 97.61962890625\n",
            "Epoch 81\tTop1 Train accuracy 72.65280151367188\tTop1 Test accuracy: 64.40673828125\tTop5 test acc: 97.69287109375\n",
            "Epoch 82\tTop1 Train accuracy 72.67578125\tTop1 Test accuracy: 64.73388671875\tTop5 test acc: 97.68798828125\n",
            "Epoch 83\tTop1 Train accuracy 72.53331756591797\tTop1 Test accuracy: 64.25537109375\tTop5 test acc: 97.5537109375\n",
            "Epoch 84\tTop1 Train accuracy 73.38809967041016\tTop1 Test accuracy: 64.12109375\tTop5 test acc: 97.79052734375\n",
            "Epoch 85\tTop1 Train accuracy 72.69991302490234\tTop1 Test accuracy: 64.658203125\tTop5 test acc: 97.75146484375\n",
            "Epoch 86\tTop1 Train accuracy 72.67578125\tTop1 Test accuracy: 64.384765625\tTop5 test acc: 97.57568359375\n",
            "Epoch 87\tTop1 Train accuracy 72.79296875\tTop1 Test accuracy: 64.21142578125\tTop5 test acc: 97.7783203125\n",
            "Epoch 88\tTop1 Train accuracy 72.8883285522461\tTop1 Test accuracy: 64.2529296875\tTop5 test acc: 97.62939453125\n",
            "Epoch 89\tTop1 Train accuracy 72.67578125\tTop1 Test accuracy: 64.35791015625\tTop5 test acc: 97.7587890625\n",
            "Epoch 90\tTop1 Train accuracy 73.34099578857422\tTop1 Test accuracy: 64.10888671875\tTop5 test acc: 97.9150390625\n",
            "Epoch 91\tTop1 Train accuracy 72.72863006591797\tTop1 Test accuracy: 64.83154296875\tTop5 test acc: 97.724609375\n",
            "Epoch 92\tTop1 Train accuracy 72.23116302490234\tTop1 Test accuracy: 64.32373046875\tTop5 test acc: 97.88330078125\n",
            "Epoch 93\tTop1 Train accuracy 73.29503631591797\tTop1 Test accuracy: 64.14306640625\tTop5 test acc: 97.71240234375\n",
            "Epoch 94\tTop1 Train accuracy 72.91704559326172\tTop1 Test accuracy: 64.60693359375\tTop5 test acc: 97.69287109375\n",
            "Epoch 95\tTop1 Train accuracy 72.890625\tTop1 Test accuracy: 64.53369140625\tTop5 test acc: 97.822265625\n",
            "Epoch 96\tTop1 Train accuracy 73.0055160522461\tTop1 Test accuracy: 63.63037109375\tTop5 test acc: 97.6220703125\n",
            "Epoch 97\tTop1 Train accuracy 73.1468276977539\tTop1 Test accuracy: 63.9404296875\tTop5 test acc: 97.55126953125\n",
            "Epoch 98\tTop1 Train accuracy 73.4742660522461\tTop1 Test accuracy: 64.25048828125\tTop5 test acc: 97.5537109375\n",
            "Epoch 99\tTop1 Train accuracy 73.14913177490234\tTop1 Test accuracy: 64.29443359375\tTop5 test acc: 97.60498046875\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  top1_train_accuracy = 0\n",
        "  for counter, (x_batch, y_batch) in enumerate(train_loader):\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    logits = model(x_batch)\n",
        "    loss = criterion(logits, y_batch)\n",
        "    top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "    top1_train_accuracy += top1[0]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  top1_train_accuracy /= (counter + 1)\n",
        "  top1_accuracy = 0\n",
        "  top5_accuracy = 0\n",
        "  for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    logits = model(x_batch)\n",
        "  \n",
        "    top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
        "    top1_accuracy += top1[0]\n",
        "    top5_accuracy += top5[0]\n",
        "  \n",
        "  top1_accuracy /= (counter + 1)\n",
        "  top5_accuracy /= (counter + 1)\n",
        "  print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()}\\tTop5 test acc: {top5_accuracy.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtYqHZirMNZk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Copy of mini-batch-logistic-regression-evaluator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "149b9ce8fb68473a837a77431c12281a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a88c31d74f5c40a2b24bcff5a35d216c",
              "IPY_MODEL_60c6150177694717a622936b830427b5"
            ],
            "layout": "IPY_MODEL_88cd3db2831e4c13a4a634709700d6b2"
          }
        },
        "5901c2829a554c8ebbd5926610088041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c6150177694717a622936b830427b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f82234388e4701a02a9f68a177193a",
            "placeholder": "​",
            "style": "IPY_MODEL_957362a11d174407979cf17012bf9208",
            "value": " 2640404480/? [00:51&lt;00:00, 32685718.58it/s]"
          }
        },
        "88cd3db2831e4c13a4a634709700d6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957362a11d174407979cf17012bf9208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4f82234388e4701a02a9f68a177193a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88c31d74f5c40a2b24bcff5a35d216c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5901c2829a554c8ebbd5926610088041",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dba019efadee4fdc8c799f309b9a7e70",
            "value": 1
          }
        },
        "dba019efadee4fdc8c799f309b9a7e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
